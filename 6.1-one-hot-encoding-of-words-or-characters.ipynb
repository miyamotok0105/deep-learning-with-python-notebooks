{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.1-one-hot-encoding-of-words-or-characters.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Ikf-pIBwEL1E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"4b88ec12-fc42-4096-c26d-d13e3624de5c","executionInfo":{"status":"ok","timestamp":1527913606467,"user_tz":-540,"elapsed":971,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.6'"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"Zv4m2huDfxjm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"e3413248-a1d3-4a2b-e96f-9d0ac25c2d1d","executionInfo":{"status":"ok","timestamp":1527913609499,"user_tz":-540,"elapsed":2892,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["!pip install cython"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.28.3)\r\n"],"name":"stdout"}]},{"metadata":{"id":"BIk2L2omcFDY","colab_type":"text"},"cell_type":"markdown","source":["# 6章 テキストとシーケンスのためのディープラーニング"]},{"metadata":{"id":"Lt8nPB27cQED","colab_type":"text"},"cell_type":"markdown","source":["６章ではテキスト、時系列データについて取り上げる。基本的なアルゴリズみはRNNと1D-CNN。    \n","\n","- 記事のトピックや書籍の著者を識別する文章の分類と時系列データの分類    \n","- ２つの文章や２つの株式指標がどれくらい深く関連しているか推定する時系列データの比較    \n","- 英語の文章をフランス語に翻訳するseq2seq    \n","- ツイートや映画レビューの感情を肯定と否定で感情分類    \n","- 最近の気象データに基づいて特定の場所の天気を予測する時系列予測    \n","\n","    \n","IMDbデータセットで感情分類と気温の予測。をする。"]},{"metadata":{"id":"d1fQ-rmhdNh6","colab_type":"text"},"cell_type":"markdown","source":["# テキストデータの操作"]},{"metadata":{"id":"NLf5cCU5dQKs","colab_type":"text"},"cell_type":"markdown","source":["テキストは最も広く使用されてるシーケンスデータの一つ。文字または単語のシーケンスと解釈。テキストを使って自然言語理解(NLU Natural language understanding)を生成できる。    \n","テキストの分割に使用できる単位（単語、文字、Nグラム）のことをトークンという。テキストをベクトル化するプロセスは何かしらのトークン化をしている。この数値ベクトルはシーケンステンソルにまとめられてDNNに提供される。    \n","\n","ベクトルをシーケンスに紐づける方法には何種類かある。    \n","トークンのone-hotエンコーディング、トークン埋め込み（token embedding）の２つを紹介。    \n","\n"]},{"metadata":{"id":"RKMo038GdmGj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YHkIlKb0dmDW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"TlnNCdseEL1L","colab_type":"text"},"cell_type":"markdown","source":["# 単語と文字の one-hotエンコーディング\n","\n","one-hotエンコーディングは、トークンをベクトルに変換する一般的手法。\n","\n","\n","\n","This notebook contains the first code sample found in Chapter 6, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n","\n","----\n","\n","One-hot encoding is the most common, most basic way to turn a token into a vector. You already saw it in action in our initial IMDB and \n","Reuters examples from chapter 3 (done with words, in our case). It consists in associating a unique integer index to every word, then \n","turning this integer index i into a binary vector of size N, the size of the vocabulary, that would be all-zeros except for the i-th \n","entry, which would be 1.\n","\n","Of course, one-hot encoding can be done at the character level as well. To unambiguously drive home what one-hot encoding is and how to \n","implement it, here are two toy examples of one-hot encoding: one for words, the other for characters.\n","\n"]},{"metadata":{"id":"dIPu7pCeEL1M","colab_type":"text"},"cell_type":"markdown","source":["Word level one-hot encoding (toy example):"]},{"metadata":{"id":"wyEUQGlpEL1N","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"16ee3c68-a43a-4b11-c13b-a843b7f99001","executionInfo":{"status":"ok","timestamp":1527909179646,"user_tz":-540,"elapsed":818,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","samples = 'The cat sat on the mat.'\n","#split関数は空白ごとに分割する\n","print(samples.split())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['The', 'cat', 'sat', 'on', 'the', 'mat.']\n"],"name":"stdout"}]},{"metadata":{"id":"KZVtazM5etuT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"9c84f28a-da8f-408c-cba8-13cd202ca452","executionInfo":{"status":"ok","timestamp":1527909346072,"user_tz":-540,"elapsed":1078,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","\n","#初期データ。サンプルごとにエントリが１つ含まれている。\n","#この単純な例ではサンプルは単なる１つの文章だが、文章全体でも良い。\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# データに含まれている全てのトークンのインデックスを構築\n","token_index = {}\n","for sample in samples:\n","    #１文を単語に分割して、単語を辞書に溜め込む\n","    #辞書からユニークなワードがないか調べて、未知語は辞書に登録する。\n","    for word in sample.split():\n","        if word not in token_index:\n","            # 文字の辞書とindexを設定する\n","            token_index[word] = len(token_index) + 1\n","\n","print(token_index)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n"],"name":"stdout"}]},{"metadata":{"id":"ovk-gJO3gkV8","colab_type":"text"},"cell_type":"markdown","source":["この辞書作成部分はpythonより低レイヤーのc、c++で書いたり、並列化しやすいjava、scala、goなどで書いた方がいい場合もあると思う。"]},{"metadata":{"id":"WDELI25sf2SK","colab_type":"text"},"cell_type":"markdown","source":["せっかくの休みなんでcython(サイソン)使ってみる。\n","    \n","https://qiita.com/kenmatsu4/items/7c08a85e41741e95b9ba"]},{"metadata":{"id":"1iOBzgwxf-X0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install cython"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uqY1_jfGfvOq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"14ecc85e-bd2d-4bb9-b8b4-0ac8132056fa","executionInfo":{"status":"ok","timestamp":1527913618073,"user_tz":-540,"elapsed":874,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["%load_ext Cython"],"execution_count":28,"outputs":[{"output_type":"stream","text":["The Cython extension is already loaded. To reload it, use:\n","  %reload_ext Cython\n"],"name":"stdout"}]},{"metadata":{"id":"j1bXTckwgUrk","colab_type":"text"},"cell_type":"markdown","source":["%%cythonをはじめに書くとjupyterでcythonがかけるよう。-nで名前をつけとくと後から便利らしい。"]},{"metadata":{"id":"4mUVJ8FXf8cs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%%cython -n test_cython_code\n","def fib(int n):\n","    cdef int i\n","    cdef double a=0.0, b=1.0\n","\n","    for i in range(n):\n","        a, b = a+b, a\n","    return a\n","\n","def primes(int kmax):\n","    cdef int n, k, i\n","    cdef int p[1000]\n","    result = []\n","\n","    if kmax > 1000:\n","        kmax = 1000\n","\n","    k = 0\n","    n = 2\n","    while k < kmax:\n","        i = 0\n","        while i < k and n % p[i] != 0:\n","            i += 1\n","\n","        if i == k:\n","            p[k] = n\n","            k += 1\n","            result.append(n)\n","        n += 1\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Sq98jfpigLJc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"374ecc73-8748-4470-c889-24054e58c6ca","executionInfo":{"status":"ok","timestamp":1527909498015,"user_tz":-540,"elapsed":1110,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["print(fib(90))\n","print(primes(20))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2.880067194370816e+18\n","[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n"],"name":"stdout"}]},{"metadata":{"id":"m_KhVppkgfOJ","colab_type":"text"},"cell_type":"markdown","source":["とりま動いた。"]},{"metadata":{"id":"OE0K0xyDrd3J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","def make_token_index_py():\n","    token_index = {}\n","    for sample in samples:\n","        for word in sample.split():\n","            if word not in token_index:\n","                token_index[word] = len(token_index) + 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4gevzrgdrv-W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"52711e1c-2aae-40ca-c50c-44759832303d","executionInfo":{"status":"ok","timestamp":1527913820214,"user_tz":-540,"elapsed":944,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["timeit -n2 -r3 make_token_index_py()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["2 loops, best of 3: 3.17 µs per loop\n"],"name":"stdout"}]},{"metadata":{"id":"1bWjwC8pgehh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%%cython -n make_token_index_1\n","\n","import numpy as np\n","cimport numpy as np #cimport使用\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","def make_token_index_cy():\n","    token_index = {}\n","    for sample in samples:\n","        for word in sample.split():\n","            if word not in token_index:\n","                token_index[word] = len(token_index) + 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mqgweewqgepc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"7b514b42-7bdc-4788-d34d-d41b58eb4ff4","executionInfo":{"status":"ok","timestamp":1527913824316,"user_tz":-540,"elapsed":747,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["timeit -n2 -r3 make_token_index_cy()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["2 loops, best of 3: 1.68 µs per loop\n"],"name":"stdout"}]},{"metadata":{"id":"r8hf8B2ir-Q1","colab_type":"text"},"cell_type":"markdown","source":["何も書き換えてないのに早いじゃないか。"]},{"metadata":{"id":"3Ld8tnoxxBai","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"d9e4f452-fa5a-4225-ff7a-6093e346b73c","executionInfo":{"status":"ok","timestamp":1527913918254,"user_tz":-540,"elapsed":1842,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["!ls"],"execution_count":48,"outputs":[{"output_type":"stream","text":["datalab\r\n"],"name":"stdout"}]},{"metadata":{"id":"P8xl1eoIvI8w","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%%cython -n make_token_index_2\n","\n","import numpy as np\n","cimport numpy as np\n","\n","cdef list samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","# samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","def make_token_index_cy_def_type():\n","    cdef dict token_index = {}\n","#     token_index = {}\n","    for sample in samples:\n","        for word in sample.split():\n","            if word not in token_index:\n","                token_index[word] = len(token_index) + 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vTKStcN1wcko","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":959},"outputId":"6cd3c872-eb54-4702-cdad-f46f0f0ab1d5","executionInfo":{"status":"error","timestamp":1527913999275,"user_tz":-540,"elapsed":925,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["timeit -n2 -r3 make_token_index_cy_def_type()"],"execution_count":52,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-0a6e5206e28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit -n2 -r3 make_token_index_cy_def_type()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1060\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'make_token_index_cy_def_type' is not defined"]}]},{"metadata":{"id":"Hu4ZdDCDxZoG","colab_type":"text"},"cell_type":"markdown","source":["型指定しようとしたけど、なんかエラってる。一旦置いておこう。"]},{"metadata":{"id":"81LVZLDn4Fww","colab_type":"text"},"cell_type":"markdown","source":["トークン一覧をtoken_indexに格納して、ワンホットエンコーディングする"]},{"metadata":{"id":"boS53I4_4WV4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":776},"outputId":"b58f8b65-02c2-40bd-a62e-ba6ad4c7cc41","executionInfo":{"status":"ok","timestamp":1527915958991,"user_tz":-540,"elapsed":788,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import numpy as np\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","token_index = {}\n","for sample in samples:\n","    for word in sample.split():\n","        if word not in token_index:\n","            token_index[word] = len(token_index) + 1\n","print(token_index)\n","\n","#次にサンプルをベクトル化する\n","#サンプルごとに最初のmax_length個の単語だけを考慮\n","max_length = 10\n","\n","#結果の格納場所\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","print(results.shape)\n","print(results)\n","\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        index = token_index.get(word)\n","        results[i, j, index] = 1.\n","\n","print(results)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n","(2, 10, 11)\n","[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n","[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"],"name":"stdout"}]},{"metadata":{"id":"3xr-EK9K5psN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"921e1c8a-312d-4f59-d9c5-19f9ee52517a","executionInfo":{"status":"ok","timestamp":1527916185291,"user_tz":-540,"elapsed":789,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import string\n","print(repr(string.printable))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'\n"],"name":"stdout"}]},{"metadata":{"id":"UNyKyXbJEL1Q","colab_type":"text"},"cell_type":"markdown","source":["### 文字レベルでの単純なone-hotエンコーディング"]},{"metadata":{"id":"zDkmKrqQEL1R","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":151},"outputId":"3184c0f5-753c-4db0-f935-ffe242448092","executionInfo":{"status":"ok","timestamp":1527916365044,"user_tz":-540,"elapsed":1526,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["import string\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","characters = string.printable  # All printable ASCII characters.\n","#スマートな書き方の印象\n","#zipでset型とrangeからでたlistが回って、dictにまとめてる。\n","token_index = dict(zip(characters, range(1, len(characters) + 1)))\n","print(\"token_index\", list(token_index)[:10])\n","\n","max_length = 50\n","#ここもzerosのshapeをsamplesのlenとmax_lenghtとtoken_indexのmaxで作ってる。\n","#先にshapeを作ってるのでcythonにしても早そう。\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","for i, sample in enumerate(samples):\n","    for j, character in enumerate(sample[:max_length]):\n","        index = token_index.get(character) #getでdictからindexを抜き出す\n","        results[i, j, index] = 1. #ワンホットになる\n","print(results[0])"],"execution_count":59,"outputs":[{"output_type":"stream","text":["token_index ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"YWbEEbIWEL1T","colab_type":"text"},"cell_type":"markdown","source":["Note that Keras has built-in utilities for doing one-hot encoding text at the word level or character level, starting from raw text data. \n","This is what you should actually be using, as it will take care of a number of important features, such as stripping special characters \n","from strings, or only taking into the top N most common words in your dataset (a common restriction to avoid dealing with very large input \n","vector spaces)."]},{"metadata":{"id":"BCqec4oeEL1U","colab_type":"text"},"cell_type":"markdown","source":["### Kerasを使った単語レベルでのone-hotエンコーディング"]},{"metadata":{"id":"vy92WzQy7fOG","colab_type":"text"},"cell_type":"markdown","source":["kerasには便利なtoknizer関数がある。"]},{"metadata":{"id":"o77088tuEL1U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"cad53aa0-e8aa-4c42-cea9-6505e3f81d88","executionInfo":{"status":"ok","timestamp":1527916683142,"user_tz":-540,"elapsed":1664,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 出現頻度が最も高い1000個の単語だけ処理する\n","#トークナイザー作成\n","tokenizer = Tokenizer(num_words=1000)\n","#単語インデックス構築\n","tokenizer.fit_on_texts(samples)\n","\n","#文字列の整数のインデックスのリストに変換\n","sequences = tokenizer.texts_to_sequences(samples)\n","\n","print(sequences)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"],"name":"stdout"}]},{"metadata":{"id":"Mc7kOLShIH-a","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"44105da0-1e87-40c1-cf9c-e912ead09a1c","executionInfo":{"status":"ok","timestamp":1527917004716,"user_tz":-540,"elapsed":740,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["#2値のone-hotエンコーディング表現を取得。one-hot以外のモードもある。\n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n","print(\"one_hot_results \", one_hot_results)\n","\n","# tokenizerが計算した単語のインデックスを復元\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":61,"outputs":[{"output_type":"stream","text":["one_hot_results  [[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n","Found 9 unique tokens.\n"],"name":"stdout"}]},{"metadata":{"id":"Tv6e3ywa9w6k","colab_type":"text"},"cell_type":"markdown","source":["‘binary‘: デフォルト。文章に存在するかどうかのみ。    \n","‘count‘: 文字のカウント。    \n","‘tfidf‘: 全体頻度割る文字のカウント。    \n","‘freq‘: 全体単語頻度。    "]},{"metadata":{"id":"HUvq3gha885y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":151},"outputId":"a6aa60a9-aa72-4c93-a75c-77a75b351512","executionInfo":{"status":"ok","timestamp":1527917145046,"user_tz":-540,"elapsed":1397,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["#いろんなtexts_to_matrix\n","for mode in ['binary', 'count', 'tfidf', 'freq']:\n","    matrix = tokenizer.texts_to_matrix(samples, mode) \n","    print(\"matrix \", \"mode: \", mode, matrix)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["matrix  mode:  binary [[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n","matrix  mode:  count [[0. 2. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n","matrix  mode:  tfidf [[0.         0.86490296 0.69314718 ... 0.         0.         0.        ]\n"," [0.         0.51082562 0.         ... 0.         0.         0.        ]]\n","matrix  mode:  freq [[0.         0.33333333 0.16666667 ... 0.         0.         0.        ]\n"," [0.         0.2        0.         ... 0.         0.         0.        ]]\n"],"name":"stdout"}]},{"metadata":{"id":"65CxaSmGGAkA","colab_type":"text"},"cell_type":"markdown","source":["text_to_word_sequenceとsetの組み合わせ便利そうだけど、語彙増えると分割しないとメモリで死にそう"]},{"metadata":{"id":"Zvr4BDhjFwHa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"292246a1-f17a-4003-b173-798d5eff8061","executionInfo":{"status":"ok","timestamp":1527919384679,"user_tz":-540,"elapsed":1651,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["#https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n","from keras.preprocessing.text import text_to_word_sequence\n","text = 'The quick brown fox jumped over the lazy dog.'\n","words = set(text_to_word_sequence(text))\n","vocab_size = len(words)\n","print(words)\n","print(vocab_size)"],"execution_count":74,"outputs":[{"output_type":"stream","text":["{'jumped', 'the', 'fox', 'dog', 'lazy', 'over', 'brown', 'quick'}\n","8\n"],"name":"stdout"}]},{"metadata":{"id":"DHauA3EYGg5p","colab_type":"text"},"cell_type":"markdown","source":["one_hot関数ってのもある"]},{"metadata":{"id":"GErZ2mSVGK-h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"ae0381b4-3566-402f-d157-9756d34466e2","executionInfo":{"status":"ok","timestamp":1527919481790,"user_tz":-540,"elapsed":1479,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.preprocessing.text import one_hot\n","from keras.preprocessing.text import text_to_word_sequence\n","text = 'The quick brown fox jumped over the lazy dog.'\n","words = set(text_to_word_sequence(text))\n","vocab_size = len(words)\n","print(vocab_size)\n","result = one_hot(text, round(vocab_size*1.3))\n","print(result)"],"execution_count":75,"outputs":[{"output_type":"stream","text":["8\n","[2, 7, 5, 2, 2, 1, 2, 8, 3]\n"],"name":"stdout"}]},{"metadata":{"id":"jFrG1h4LGqRI","colab_type":"text"},"cell_type":"markdown","source":["hashing_trick。md5指定版。"]},{"metadata":{"id":"SZBSSjOyGlyx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":84},"outputId":"360d4c38-f839-4da7-f094-2b4c818cd7c3","executionInfo":{"status":"ok","timestamp":1527919693130,"user_tz":-540,"elapsed":838,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.preprocessing.text import hashing_trick\n","from keras.preprocessing.text import text_to_word_sequence\n","text = 'The quick brown fox jumped over the lazy dog.'\n","words = set(text_to_word_sequence(text))\n","vocab_size = len(words)\n","print(vocab_size)\n","#2個目の引数がハッシュ空間の次元。結果を見ると早速index被ってない？\n","result = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n","print(result)\n","result = hashing_trick(text, round(vocab_size*2), hash_function='md5')\n","print(result)\n","result = hashing_trick(text, round(vocab_size*3), hash_function='md5')\n","print(result)"],"execution_count":77,"outputs":[{"output_type":"stream","text":["8\n","[6, 4, 1, 2, 7, 5, 6, 2, 6]\n","[15, 10, 13, 14, 10, 8, 15, 8, 6]\n","[18, 20, 16, 12, 22, 3, 18, 6, 17]\n"],"name":"stdout"}]},{"metadata":{"id":"1fcvXMXg8ZGJ","colab_type":"text"},"cell_type":"markdown","source":["### Toknizerの保存と読み込み"]},{"metadata":{"id":"plU383Pw-r8W","colab_type":"text"},"cell_type":"markdown","source":["トークンが多くなったら毎回トークナイズしたくない場合もある。その場合は何かしらシリアライズしたい。    \n","\n","tokenizerをpickleで塩漬けにする方法"]},{"metadata":{"id":"QH3hjxYC-opH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"f9a647ca-d416-4317-adc2-df808a75769e","executionInfo":{"status":"ok","timestamp":1527917552450,"user_tz":-540,"elapsed":570,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(samples)\n","sequences = tokenizer.texts_to_sequences(samples)\n","results_vec = tokenizer.texts_to_matrix(samples, mode='binary')\n","word_index = tokenizer.word_index\n","print(\"sequences\", sequences) #単語ID一覧\n","print(\"results_vec\", results_vec) #ワンホット"],"execution_count":63,"outputs":[{"output_type":"stream","text":["sequences [[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n","results_vec [[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"84e18NtW8fgu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pickle\n","# saving\n","with open('tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XSqw7YFk_2xm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"ebdb9056-675e-4dd8-e710-1fd20f9ea797","executionInfo":{"status":"ok","timestamp":1527917804084,"user_tz":-540,"elapsed":1760,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["!ls"],"execution_count":67,"outputs":[{"output_type":"stream","text":["datalab  tokenizer.pickle\r\n"],"name":"stdout"}]},{"metadata":{"id":"Hcq_OxJs_xTS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# loading\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"05b43iQS_yz5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"9f63bd93-d4de-4325-d3e6-d84938aef860","executionInfo":{"status":"ok","timestamp":1527917792031,"user_tz":-540,"elapsed":773,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["sequences = tokenizer.texts_to_sequences(samples)\n","results_vec = tokenizer.texts_to_matrix(samples, mode='binary')\n","word_index = tokenizer.word_index\n","print(\"sequences\", sequences) #単語ID一覧\n","print(\"results_vec\", results_vec) #ワンホット"],"execution_count":66,"outputs":[{"output_type":"stream","text":["sequences [[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n","results_vec [[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"B28znLoFAVZM","colab_type":"text"},"cell_type":"markdown","source":["毎回データが同じなんですって場合はベクトルの方を保存してもいいと思う。"]},{"metadata":{"id":"vG8E1IfjAEjx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(samples)\n","sequences = tokenizer.texts_to_sequences(samples)\n","results_vec = tokenizer.texts_to_matrix(samples, mode='binary')\n","word_index = tokenizer.word_index\n","np.save(open(\"sequences.npy\", 'wb'), sequences)\n","np.save(open(\"results_vec.npy\", 'wb'), results_vec)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bn7wZSUIAoza","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":50},"outputId":"7e3cdecc-33d9-479e-a253-83ebe97a3442","executionInfo":{"status":"ok","timestamp":1527918095814,"user_tz":-540,"elapsed":2071,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["!ls"],"execution_count":71,"outputs":[{"output_type":"stream","text":["datalab      results_vec.npy  sequences.npy\r\n","results_vec  sequences\t      tokenizer.pickle\r\n"],"name":"stdout"}]},{"metadata":{"id":"E61HTUWJAqgx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"88f9d944-74bb-4b35-8e6d-bba95c17a6b9","executionInfo":{"status":"ok","timestamp":1527918124509,"user_tz":-540,"elapsed":787,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["sequences2 = np.load(\"sequences.npy\")\n","results_vec2 = np.load(\"results_vec.npy\")\n","print(\"sequences\", sequences2) #単語ID一覧\n","print(\"results_vec\", results_vec2) #ワンホット"],"execution_count":72,"outputs":[{"output_type":"stream","text":["sequences [list([1, 2, 3, 4, 1, 5]) list([1, 6, 7, 8, 9])]\n","results_vec [[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"Hj3ZRe4uCa7X","colab_type":"text"},"cell_type":"markdown","source":["エンコーディング方法にone-hotハッシュトリックというものもある。役立つのは語彙に含まれている一意のトークンの数がそのまま処理するには多すぎる場合。    \n","単語をインデックス参照する代わりに、単語を固定サイズのベクトルにハッシュ化する。    \n","軽量ハッシュを使用。単語インデックスを明示的に保持しないでメモリを節約する。データのオンラインコーディングを可能にする。    \n","利用可能なデータが全て揃う前に、トークンベクトルを生成できる。    \n","\n","欠点はハッシュ衝突の恐れがある。    \n","\n","ハッシュ衝突の可能性が低くなるのは、ハッシュ化の対象となる一意なトークンの総数よりもハッシュ空間の次元数の方が大きい場合。    \n","つまりハッシュ空間でかくしとけってか。    \n","\n"]},{"metadata":{"id":"QO1t1enAEL1Y","colab_type":"text"},"cell_type":"markdown","source":["### ハッシュトリックを用いた単語レベルの単純なone-hotエンコーディング"]},{"metadata":{"id":"EnOgf5QQHy_7","colab_type":"text"},"cell_type":"markdown","source":["kerasの関数使えばいいけど、直に書くとこの雰囲気。"]},{"metadata":{"id":"i-xZIUnEEL1Z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":269},"outputId":"14941532-0732-4454-831b-fc6cde293207","executionInfo":{"status":"ok","timestamp":1527919850065,"user_tz":-540,"elapsed":988,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","#単語をサイズが1000ベクトルとして格納なのでハッシュ空間が1000\n","#ボキャブラリ数が1000に近くなるとハッシュ衝突が発生する。\n","dimensionality = 1000\n","max_length = 10\n","\n","results = np.zeros((len(samples), max_length, dimensionality))\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        #単語をハッシュ化して、0〜1000のランダム整数に変換\n","        index = abs(hash(word)) % dimensionality\n","        results[i, j, index] = 1.\n","        \n","print(results)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n"],"name":"stdout"}]},{"metadata":{"id":"vYg0wLezJGdI","colab_type":"text"},"cell_type":"markdown","source":["hashing_trickは多分こんな感じ？"]},{"metadata":{"id":"8DzPLaXgHq37","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":235},"outputId":"113429fe-b52c-4f4a-822e-18b2412a36a2","executionInfo":{"status":"ok","timestamp":1527920208453,"user_tz":-540,"elapsed":785,"user":{"displayName":"宮本圭一郎","photoUrl":"//lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s50-c-k-no/photo.jpg","userId":"100227668169464343249"}}},"cell_type":"code","source":["from keras.utils import to_categorical\n","from keras.preprocessing.text import hashing_trick\n","from keras.preprocessing.text import text_to_word_sequence\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","dimensionality = 1000\n","max_length = 10\n","\n","for i, sample in enumerate(samples):\n","    #単語をハッシュ化して、0〜1000のランダム整数に変換\n","    result = hashing_trick(sample, dimensionality, hash_function='md5')\n","    print(result)\n","    print(to_categorical(result))"],"execution_count":80,"outputs":[{"output_type":"stream","text":["[132, 759, 622, 379, 132, 962]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n","[132, 168, 822, 28, 128]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"xL3Su4ovIh27","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}